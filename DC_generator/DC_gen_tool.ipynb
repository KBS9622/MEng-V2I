{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from sympy import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit, least_squares\n",
    "from scipy.optimize import minimize as sp_minimize\n",
    "from scipy import special\n",
    "from lmfit import minimize, Minimizer, Parameters, Parameter, report_fit\n",
    "import matplotlib.pyplot as plt\n",
    "import lmfit\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_data(file_name, subdir=''):\n",
    "    \"\"\"\n",
    "    Loads data from .csv file in to DataFrame\n",
    "\n",
    "    :param file_name: .csv file name in string\n",
    "    :param subdir: optional parameter to specify the subdirectory of the file\n",
    "    :return: extracted data in DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    file_dir = os.path.realpath('../')\n",
    "    print(file_dir)\n",
    "    for root, dirs, files in os.walk(file_dir):\n",
    "        if root.endswith(subdir):\n",
    "            for name in files:\n",
    "                if name == file_name:\n",
    "                    file_path = os.path.join(root, name)\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LF_Noise(component = 1):\n",
    "    \"\"\" Inital parameters and bounds for each paramter according to LF (0-0.01Hz)in the paper\n",
    "    \"\"\"\n",
    "    LMparams = Parameters()\n",
    "\n",
    "    # The code below is to load the initial paramters if we are running the NLLSR on all 3 components at once\n",
    "\n",
    "    LMparams.add('A1_FS', value = 10.)\n",
    "    LMparams.add('A2_FS', value = 10.)\n",
    "    LMparams.add('A3_FS', value = 10.)\n",
    "    LMparams.add('w1_FS', value = 0, min = 0, max = 0.01*2*math.pi)\n",
    "    LMparams.add('w2_FS', value = 0.005*2*math.pi, min = 0, max = 0.01*2*math.pi)\n",
    "    LMparams.add('w3_FS', value = 0.01*2*math.pi, min = 0, max = 0.01*2*math.pi)\n",
    "    LMparams.add('phi1_FS', value = 0, min = -math.pi, max = math.pi)\n",
    "    LMparams.add('phi2_FS', value = 0, min = -math.pi, max = math.pi)\n",
    "    LMparams.add('phi3_FS', value = 0, min = -math.pi, max = math.pi)\n",
    "\n",
    "    # The code below is to load the initial paramters if we are running the NLLSR on one component at a time\n",
    "\n",
    "    # if component == 1:\n",
    "    #     LMparams.add('A_FS', value = 10.)\n",
    "    #     LMparams.add('w_FS', value = 0, min = 0, max = 0.01*2*math.pi)\n",
    "    #     LMparams.add('phi_FS', value = 0, min = -math.pi, max = math.pi)\n",
    "    # elif component == 2:\n",
    "    #     LMparams.add('A_FS', value = 10.)\n",
    "    #     LMparams.add('w_FS', value = 0.005*2*math.pi, min = 0, max = 0.01*2*math.pi)\n",
    "    #     LMparams.add('phi_FS', value = 0, min = -math.pi, max = math.pi)\n",
    "    # elif component == 3:\n",
    "    #     LMparams.add('A_FS', value = 10.)\n",
    "    #     LMparams.add('w_FS', value = 0.01*2*math.pi, min = 0, max = 0.01*2*math.pi)\n",
    "    #     LMparams.add('phi_FS', value = 0, min = -math.pi, max = math.pi)\n",
    "\n",
    "    return LMparams\n",
    "\n",
    "def MF_Noise(component = 1):\n",
    "    \"\"\" Inital parameters and bounds for each paramter according to MF (0.01-0.25Hz) in the paper\n",
    "    \"\"\"\n",
    "    LMparams = Parameters()\n",
    "\n",
    "    # The code below is to load the initial paramters if we are running the NLLSR on all 3 components at once\n",
    "\n",
    "    LMparams.add('A1_FS', value = 10.)\n",
    "    LMparams.add('A2_FS', value = 10.)\n",
    "    LMparams.add('A3_FS', value = 10.)\n",
    "    LMparams.add('w1_FS', value = 0.02*2*math.pi, min = 0.01*2*math.pi, max = 0.25*2*math.pi)\n",
    "    LMparams.add('w2_FS', value = 0.03*2*math.pi, min = 0.01*2*math.pi, max = 0.25*2*math.pi)\n",
    "    LMparams.add('w3_FS', value = 0.03*2*math.pi, min = 0.01*2*math.pi, max = 0.25*2*math.pi)\n",
    "    LMparams.add('phi1_FS', value = 0, min = -math.pi, max = math.pi)\n",
    "    LMparams.add('phi2_FS', value = 0, min = -math.pi, max = math.pi)\n",
    "    LMparams.add('phi3_FS', value = 0, min = -math.pi, max = math.pi)\n",
    "\n",
    "    # The code below is to load the initial paramters if we are running the NLLSR on one component at a time\n",
    "\n",
    "    # if component == 1:\n",
    "    #     LMparams.add('A_FS', value = 10.)\n",
    "    #     LMparams.add('w_FS', value = 0.02*2*math.pi, min = 0.01*2*math.pi, max = 0.25*2*math.pi)\n",
    "    #     LMparams.add('phi_FS', value = 0, min = -math.pi, max = math.pi)\n",
    "    # elif component == 2:\n",
    "    #     LMparams.add('A_FS', value = 10.)\n",
    "    #     LMparams.add('w_FS', value = 0.03*2*math.pi, min = 0.01*2*math.pi, max = 0.25*2*math.pi)\n",
    "    #     LMparams.add('phi_FS', value = 0, min = -math.pi, max = math.pi)\n",
    "    # elif component == 3:\n",
    "    #     LMparams.add('A_FS', value = 10.)\n",
    "    #     LMparams.add('w_FS', value = 0.03*2*math.pi, min = 0.01*2*math.pi, max = 0.25*2*math.pi)\n",
    "    #     LMparams.add('phi_FS', value = 0, min = -math.pi, max = math.pi)\n",
    "\n",
    "    return LMparams\n",
    "\n",
    "def HF_Noise(component = 1):\n",
    "    \"\"\" Inital parameters and bounds for each paramter according to HF (0.25-0.5Hz) in the paper\n",
    "    \"\"\"\n",
    "    LMparams = Parameters()\n",
    "\n",
    "    # The code below is to load the initial paramters if we are running the NLLSR on all 3 components at once\n",
    "\n",
    "    LMparams.add('A1_FS', value = 1.)\n",
    "    LMparams.add('A2_FS', value = 1.)\n",
    "    LMparams.add('A3_FS', value = 1.)\n",
    "    LMparams.add('w1_FS', value = 0.25*2*math.pi, min = 0.25*2*math.pi, max = 0.5*2*math.pi)\n",
    "    LMparams.add('w2_FS', value = 0.375*2*math.pi, min = 0.25*2*math.pi, max = 0.5*2*math.pi)\n",
    "    LMparams.add('w3_FS', value = 0.5*2*math.pi, min = 0.25*2*math.pi, max = 0.5*2*math.pi)\n",
    "    LMparams.add('phi1_FS', value = 0, min = -math.pi, max = math.pi)\n",
    "    LMparams.add('phi2_FS', value = 0, min = -math.pi, max = math.pi)\n",
    "    LMparams.add('phi3_FS', value = 0, min = -math.pi, max = math.pi)\n",
    "\n",
    "    # The code below is to load the initial paramters if we are running the NLLSR on one component at a time\n",
    "\n",
    "    # if component == 1:\n",
    "    #     LMparams.add('A_FS', value = 1.)\n",
    "    #     LMparams.add('w_FS', value = 0.25*2*math.pi, min = 0.25*2*math.pi, max = 0.5*2*math.pi)\n",
    "    #     LMparams.add('phi_FS', value = 0, min = -math.pi, max = math.pi)\n",
    "    # elif component == 2:\n",
    "    #     LMparams.add('A_FS', value = 1.)\n",
    "    #     LMparams.add('w_FS', value = 0.375*2*math.pi, min = 0.25*2*math.pi, max = 0.5*2*math.pi)\n",
    "    #     LMparams.add('phi_FS', value = 0, min = -math.pi, max = math.pi)\n",
    "    # elif component == 3:\n",
    "    #     LMparams.add('A_FS', value = 1.)\n",
    "    #     LMparams.add('w_FS', value = 0.5*2*math.pi, min = 0.25*2*math.pi, max = 0.5*2*math.pi)\n",
    "    #     LMparams.add('phi_FS', value = 0, min = -math.pi, max = math.pi)\n",
    "\n",
    "    return LMparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)\n",
    "random_no = random.random()\n",
    "print(round(random_no,3))\n",
    "random_no = random.random()\n",
    "print(random_no)\n",
    "\n",
    "np.random.seed(10)\n",
    "list1 = np.random.rand(5).tolist()\n",
    "random_numbers = [round(element, 2) for element in list1]\n",
    "print(random_numbers.pop())\n",
    "print(random_numbers.pop())\n",
    "print(random_numbers.pop())\n",
    "print(random_numbers.pop())\n",
    "print(random_numbers.pop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DP(object):\n",
    "    \"\"\" Module 3: Drive Pulse\n",
    "    \"\"\"\n",
    "    def __init__(self, pulse_duration):\n",
    "        \"\"\" Constructor takes in pulse duration and creates instances of inverse cdfs for each of the intersted parameters needed to\n",
    "            generate the drive pulse. Creates self.parameter dictionary containing all relevant parameters.\n",
    "        \"\"\"\n",
    "        self.pulse_duration = pulse_duration \n",
    "        self.total_t = np.linspace(0, 1000*self.pulse_duration, (1000*self.pulse_duration)+1)\n",
    "        self.accel_inv_cdf_obj = self.create_inv_cdf_objects(Acceleration())\n",
    "        self.cruising_duration_inv_cdf_obj = self.create_inv_cdf_objects(Cruising_Duration())\n",
    "        self.avg_cruising_speed_inv_cdf_obj = self.create_inv_cdf_objects(Average_Crusing_Speed())\n",
    "        self.decel_inv_cdf_obj = self.create_inv_cdf_objects(Deceleration())\n",
    "        self.random_select_params()\n",
    "        self.params = self.parameters_for_drive_cycle(self.accel_value, self.decel_value, self.cruising_duration_value, self.avg_cruising_speed_value)\n",
    "        print(self.params)\n",
    "\n",
    "\n",
    "    def create_inv_cdf_objects(self, attribute_obj):\n",
    "        \"\"\"\n",
    "        Takes in one of parameter's classes needed for driving pulse and instantiates object for the inverse_cdf\n",
    "        \"\"\"\n",
    "        #load initial gaussian parameters\n",
    "        param_obj = Gaussian_param()\n",
    "        #create a probability function object for attribute with its attribute histogram data\n",
    "        attribute_prob_obj = Probability_Functions(attribute_obj.bins, attribute_obj.data_points,2)\n",
    "        #fit the histogram\n",
    "        fitted_obj = attribute_prob_obj.NLLSR(param_obj)\n",
    "        # create inverse cdf object\n",
    "        inv_cdf_obj = inv_cdf(attribute_prob_obj)\n",
    "\n",
    "        return inv_cdf_obj\n",
    "\n",
    "    def random_select_params(self, seed = 10):\n",
    "        \"\"\"\n",
    "        Randomly generates numbers from 0 to 1 to randomly select values for parameters using their inverse cdf\n",
    "        \"\"\"\n",
    "        np.random.seed(seed)\n",
    "        list1 = np.random.rand(4).tolist()\n",
    "        random_numbers = [round(element, 2) for element in list1]\n",
    "        self.accel_value = self.accel_inv_cdf_obj.get_value(random_numbers.pop())[0]\n",
    "        # self.cruising_duration_value = self.cruising_duration_inv_cdf_obj.get_value(random_numbers.pop())[0]\n",
    "        self.cruising_duration_value = self.cruising_duration_inv_cdf_obj.get_value(0.98)[0]\n",
    "        self.avg_cruising_speed_value = self.avg_cruising_speed_inv_cdf_obj.get_value(random_numbers.pop())[0]\n",
    "        self.decel_value = self.decel_inv_cdf_obj.get_value(random_numbers.pop())[0]\n",
    "\n",
    "    def crusing_with_noise(self, time_array, velocity_noise_obj):\n",
    "        \"\"\"\n",
    "        time_array: array of timestamps to compute for corresponding velocity noise using fitted model\n",
    "        velocity_noise_obj: VN object containing fitted model and respective parameters for 3 freq components\n",
    "        \n",
    "        return:: cruising_with_noise set of speed values containing average cruising speed superimposed on velocity noise \n",
    "        \"\"\"\n",
    "        #resets time to match the specified duration of the driving pulse\n",
    "        velocity_noise_obj.set_t(time_array)\n",
    "        #returns velocity noise speed values (y axis)\n",
    "        velocity_noise = velocity_noise_obj.final_curve()\n",
    "        #adds velocity noise speed values (y axis) to static cruising speed\n",
    "        cruising_with_noise =  velocity_noise + self.params[\"cruising speed\"]\n",
    "\n",
    "        plt.plot(time_array, cruising_with_noise)\n",
    "        plt.show()\n",
    "        return cruising_with_noise\n",
    "\n",
    "    def parameters_for_drive_cycle(self, acceleration, decceleration, cruising_duration, average_cruising_speed):\n",
    "        \"\"\"\n",
    "        accepts as parameters the 4 randomly selected values from the inverse cdfs, computes other parameters and returns\n",
    "        this as a dictionary\n",
    "        \"\"\"\n",
    "        #computes acceleration time by using average cruising speed as initial speed of cruising duration\n",
    "        acceleration_time= 1000 * average_cruising_speed / acceleration\n",
    "        #computes decceleration time by using average cruising speed as final speed of cruising duration\n",
    "        decceleration_time = 1000 * average_cruising_speed / decceleration\n",
    "        #computes idle time by subtracting all other durations from total pulse duration\n",
    "        idle_time = self.total_t - acceleration_time - decceleration_time - (1000 * cruising_duration)\n",
    "        \n",
    "        #constructs parameters dictionary containing everything needed to generate driving pulse\n",
    "        parameters = {\"acceleration\": acceleration,\n",
    "                      \"decceleration\" : decceleration,\n",
    "                      \"acceleration duration\": round(acceleration_time),\n",
    "                      \"decceleration duration\": round(decceleration_time),\n",
    "                      \"cruising duration\" : round(1000 * cruising_duration),\n",
    "                      \"cruising speed\" : average_cruising_speed,\n",
    "                      \"idle duration\" : idle_time,\n",
    "                      \"total duration\": self.total_t\n",
    "                      }\n",
    "        return parameters\n",
    "\n",
    "    def generate_drive_cycle(self, velocity_noise_obj):\n",
    "        \"\"\" Function to be called from outside the class that outputs plot of generated driving pulse\n",
    "        \"\"\"\n",
    "        # Call cruising_with_noise method to return corresponding values (y axis) for cruising\n",
    "        # Inputs the whole pulse duration as cruise duration therefore extra values are present\n",
    "        print(self.total_t)\n",
    "        print(self.params[\"acceleration duration\"])\n",
    "        print(np.where(self.total_t[:]==self.params[\"acceleration duration\"]))\n",
    "        print(np.where(self.total_t[:]==self.params[\"acceleration duration\"])[0][0])\n",
    "        print(self.total_t[np.where(self.total_t[:]==self.params[\"acceleration duration\"])[0][0]:])\n",
    "        speed_while_cruising_extra_values = self.crusing_with_noise(self.total_t[np.where(self.total_t[:]==self.params[\"acceleration duration\"])[0][0]:]/1000, velocity_noise_obj)\n",
    "        # computes initial cruising speed with velocity noise\n",
    "        initial_cruising_speed = speed_while_cruising_extra_values[0]\n",
    "        # computes actual acceleartion duration using the caluclated initial speed\n",
    "        # no longer is using the estimate of initial= avergae cruising speed as in the parameters_for_drive_cycle method\n",
    "        self.params[\"acceleration duration\"] = round(1000 * initial_cruising_speed / self.params[\"acceleration\"])\n",
    "        print('accel_duration:{}'.format(self.params[\"acceleration duration\"]))\n",
    "        print(self.total_t)\n",
    "        print(1000*self.params[\"acceleration duration\"])\n",
    "        print(np.where(self.total_t[:]==self.params[\"acceleration duration\"]))\n",
    "        \n",
    "        # Retrieves x axis (time steps) and y axis (speed) values during acceleration period\n",
    "        accel_time_values = self.total_t[:np.where(self.total_t[:]==self.params[\"acceleration duration\"])[0][0]]\n",
    "        speed_during_acceleration = self.params[\"acceleration\"] * accel_time_values / 1000\n",
    "        current_time = self.params[\"acceleration duration\"]\n",
    "        \n",
    "        # Retrieves x axis (time steps) and y axis (speed) values during cruising period\n",
    "        cruising_time_values = self.total_t[np.where(self.total_t[:]==current_time)[0][0]:np.where(self.total_t[:]==current_time+self.params[\"cruising duration\"])[0][0]]\n",
    "        speed_during_cruising = speed_while_cruising_extra_values[:np.where(self.total_t[:]==self.params[\"cruising duration\"])[0][0]]\n",
    "        current_time += self.params[\"cruising duration\"]\n",
    "        \n",
    "        # Retrieves x axis (time steps) and y axis (speed) values during decceleration period\n",
    "        final_cruising_speed = speed_during_cruising[-1]\n",
    "        print(final_cruising_speed)\n",
    "        print(self.params[\"decceleration\"])\n",
    "        self.params[\"decceleration duration\"] = round(1000 * final_cruising_speed / self.params[\"decceleration\"])\n",
    "        print(self.params[\"decceleration duration\"])\n",
    "        end_time = round(current_time+self.params[\"decceleration duration\"])\n",
    "        deccel_time_values = self.total_t[np.where(self.total_t[:]==current_time)[0][0]:np.where(self.total_t[:]==end_time)[0][0]]\n",
    "        speed_during_decceleration = final_cruising_speed - (self.params[\"decceleration\"]/1000 * np.linspace(1, self.params[\"decceleration duration\"], int(self.params[\"decceleration duration\"])))\n",
    "        current_time += self.params[\"decceleration duration\"] \n",
    "        # current_time = round(current_time,3)\n",
    "        \n",
    "        # Retrieves x axis (time steps) and y axis (speed= 0) values during idle_time period\n",
    "        idle_time_values = self.total_t[np.where(self.total_t[:]==current_time)[0][0]:np.where(self.total_t[:]==self.pulse_duration)[0][0]]                                            \n",
    "        idle_time = 0 * idle_time_values\n",
    "        \n",
    "        # Plot all 4 periods on same plot to visuale driving pulse\n",
    "        plt.plot(accel_time_values, speed_during_acceleration, 'r')  \n",
    "        plt.plot(cruising_time_values, speed_during_cruising, 'b') \n",
    "        plt.plot(deccel_time_values, speed_during_decceleration, 'g') \n",
    "        plt.plot(idle_time_values, idle_time, 'r')\n",
    "        plt.show()\n",
    "\n",
    "        time_steps = np.concatenate(accel_time_values,cruising_time_values,deccel_time_values,idle_time_values)\n",
    "        speed = np.concatenate(peed_during_acceleration,speed_during_cruising,speed_during_decceleration,idle_time)\n",
    "\n",
    "        df = pd.DataFrame({'time_steps':x, 'speed':y}) \n",
    "\n",
    "        df.to_csv('generated_data.csv', index = False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DS(object):\n",
    "    \"\"\" Module 2: Drive Scenario\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DC(object):\n",
    "    \"\"\" Module 1: Drive Cycle\n",
    "    \"\"\"\n",
    "    def __init__(self, dc_length):\n",
    "        \n",
    "        t_DC = dc_length\n",
    "        sum_t_DS = 0\n",
    "        while t_DC > sum_t_DS:\n",
    "            pass\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Acceleration(object):\n",
    "    def __init__(self):\n",
    "        # self.bins = pd.DataFrame([0.2,0.4,0.6,0.8,1,1.2,1.4,1.6,1.8,2])\n",
    "        # self.data_points = pd.DataFrame([1,4,12,24,20,29,9,1,0,0])\n",
    "        self.bins = pd.DataFrame(np.linspace(0.1, 2.098, num=1000))\n",
    "        self.data_points = pd.DataFrame(np.repeat([1,4,12,24,20,29,9,1,0,0],100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cruising_Duration(object):\n",
    "    def __init__(self):\n",
    "        # self.bins = pd.DataFrame([0,12,24,36,48,60,72,84,96,108,120])\n",
    "        # data_points = pd.DataFrame([3,14,28,26,12,7,2,4,3,0,1])\n",
    "        self.bins = pd.DataFrame(np.linspace(-6, 125.88, num=1100))\n",
    "        self.data_points = pd.DataFrame(np.repeat([3,14,28,26,12,7,2,4,3,0,1],100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Average_Crusing_Speed(object):\n",
    "    def __init__(self):\n",
    "        # self.bins = pd.DataFrame([2,4,6,8,10,12,14,16,18,20])\n",
    "        # self.data_points = pd.DataFrame([0,1,2,6,18,35,22,11,4,1])\n",
    "        self.bins = pd.DataFrame(np.linspace(1, 20.98, num=1000))\n",
    "        self.data_points = pd.DataFrame(np.repeat([0,1,2,6,18,35,22,11,4,1],100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Deceleration(object):\n",
    "    def __init__(self):\n",
    "        # self.bins = pd.DataFrame([0,0.5,1,1.5,2,2.5,3,3.5,4,4.5])\n",
    "        # self.data_points = pd.DataFrame([0,0,6,14,22,20,16,13,6,3])\n",
    "        self.bins = pd.DataFrame(np.linspace(-0.25, 4.745, num=1000))\n",
    "        self.data_points = pd.DataFrame(np.repeat([0,0,6,14,22,20,16,13,6,3],100))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Extract_Hist(object):\n",
    "    def __init__(self, file_name, subdir=''):\n",
    "        self.df = load_csv_data(file_name=file_name,subdir=subdir)\n",
    "    \n",
    "    def identify_points(self):\n",
    "        self.points = self.df.copy()\n",
    "        # only get the observations for which the points are labeled\n",
    "        self.points = self.points[self.points['points']>0]\n",
    "        #print out the values of points to visually determine if there are any errors in labelling order\n",
    "        print(self.points['points'].to_numpy())\n",
    "        # identify which observations are not fully labeled (1 and 4 labelled but not 2 and 3)\n",
    "\n",
    "\n",
    "    def extract_acceleration(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'device12_oct_7_to_10_classified.csv'\n",
    "extract_obj = Extract_Hist(file_name)\n",
    "print(extract_obj.df)\n",
    "extract_obj.identify_points()\n",
    "print(extract_obj.points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gaussian_param():\n",
    "    \"\"\" Inital parameters for each Gaussian characteristic paramter \n",
    "    \"\"\"\n",
    "    LMparams = Parameters()\n",
    "    # there are two sets of values because the paper used 2 curve (n=2) to fit the distributions\n",
    "    LMparams.add('alpha_1', value = 1., min = 0)\n",
    "    LMparams.add('alpha_2', value = 1., min = 0)\n",
    "    LMparams.add('sigma_1', value = 1., min = 0)\n",
    "    LMparams.add('sigma_2', value = 1., min = 0)\n",
    "    LMparams.add('meu_1', value = 1., min = 0)\n",
    "    LMparams.add('meu_2', value = 1., min = 0)\n",
    "\n",
    "    return LMparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Probability_Functions(object):\n",
    "    def __init__(self, x, y, n):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.original_y = y\n",
    "        # the number of Gaussian distribution used to describe the data\n",
    "        self.n = n\n",
    "\n",
    "    def single_component(self, alpha_i, sigma_i, meu_i):\n",
    "        \"\"\" Returns the single Gaussian component as described in the sum of eqn (10)\n",
    "        \"\"\"\n",
    "        exp_component = -((self.x - meu_i)**2)/(2*(sigma_i**2))\n",
    "        fcn = (alpha_i/(sigma_i*math.sqrt(2*math.pi)))*np.exp(exp_component)\n",
    "        return fcn\n",
    "\n",
    "    def eqn_model(self, params):\n",
    "        \"\"\" Returns the Gaussian component sum as described in eqn (10)\n",
    "        \"\"\"\n",
    "        # runs a loop for the number of of Gaussian distibutions used to describe the data, and sums the single components \n",
    "        for component in range(1,self.n+1):\n",
    "            alpha_i = 'alpha_'+str(component)\n",
    "            sigma_i = 'sigma_'+str(component)\n",
    "            meu_i = 'meu_'+str(component)\n",
    "            if component == 1:\n",
    "                model = self.single_component(params[alpha_i],params[sigma_i],params[meu_i])\n",
    "            else:\n",
    "                model += self.single_component(params[alpha_i],params[sigma_i],params[meu_i])\n",
    "\n",
    "        return model\n",
    "\n",
    "    def fnc2min(self, params):\n",
    "        \"\"\" Returns the residuals for eqn_model\n",
    "        \"\"\"\n",
    "        return (self.y - self.eqn_model(params))\n",
    "\n",
    "    def NLLSR(self, LMparams):\n",
    "        \"\"\" Returns the result of the NLLSR using LMFit\n",
    "        \"\"\"\n",
    "        # uses least swuares method to minimize the parameters given by LMparams according to the residuals given by self.fnc2min\n",
    "        LMFitmin = Minimizer(self.fnc2min, LMparams)\n",
    "        LMFitResult = LMFitmin.minimize(method='least_squares')\n",
    "        lmfit.printfuncs.report_fit(LMFitResult.params)\n",
    "        self.params = LMFitResult.params\n",
    "\n",
    "        return LMFitResult\n",
    "\n",
    "    def single_cdf_component(self, x, alpha_i, sigma_i, meu_i):\n",
    "        \"\"\" Returns the single cdf component as described in the sum of eqn (12)\n",
    "        \"\"\"\n",
    "        erf_param = (x - meu_i)/(sigma_i * math.sqrt(2))\n",
    "        answer =  0.5 * alpha_i * (1 + special.erf(erf_param))\n",
    "\n",
    "        return answer\n",
    "\n",
    "    def cdf(self, x, params):\n",
    "        \"\"\" Returns the cdf component sum as described in eqn (12)\n",
    "        \"\"\"\n",
    "        for component in range(1,self.n+1):\n",
    "            alpha_i = 'alpha_'+str(component)\n",
    "            sigma_i = 'sigma_'+str(component)\n",
    "            meu_i ='meu_'+str(component)\n",
    "\n",
    "            if component == 1:\n",
    "                answer =  self.single_cdf_component(x, params[alpha_i], params[sigma_i], params[meu_i])\n",
    "            else:\n",
    "                answer +=  self.single_cdf_component(x, params[alpha_i], params[sigma_i], params[meu_i])\n",
    "\n",
    "        return answer\n",
    "\n",
    "    def normalised_cdf(self,x, LMparams):\n",
    "        \"\"\" Returns a normalised cdf as described in eqn (13)\n",
    "        \"\"\"\n",
    "        lim_inf_cdf = self.cdf(math.inf, LMparams)\n",
    "        answer = self.cdf(x, LMparams)/lim_inf_cdf\n",
    "\n",
    "        return answer\n",
    "\n",
    "    def normalised_single_cdf(self,x, alpha_i, sigma_i, meu_i):\n",
    "        \"\"\" normalised cdf for a SINGLE component \n",
    "        \"\"\"\n",
    "        lim_inf_cdf = self.single_cdf_component(math.inf, alpha_i, sigma_i, meu_i)\n",
    "        answer = self.single_cdf_component(x, alpha_i, sigma_i, meu_i)/lim_inf_cdf\n",
    "\n",
    "        return answer\n",
    "\n",
    "    def single_quantile_component(self, p, alpha_i, sigma_i, meu_i):\n",
    "        \"\"\" single inverse cdf component\n",
    "        \"\"\"\n",
    "        inv_erf_param = (2*p/alpha_i) - 1\n",
    "        answer =  meu_i + (sigma_i * math.sqrt(2) * special.erfinv(inv_erf_param))\n",
    "\n",
    "        return answer\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class inv_cdf(object):\n",
    "    def __init__(self, prob_obj):\n",
    "        # create a numpy array ranging from 0 to 1 with granularity of e-3\n",
    "        # the array represents the possible p values that could be input to determine the attribute value, therefore\n",
    "        # granularity of the random number generator needs to be set to e-3\n",
    "        self.x = np.arange(0,1.001,0.001)\n",
    "        # genenrate an empty array with same shape as self.x\n",
    "        self.y = np.zeros(self.x.shape)\n",
    "        # save a local version of the probability object\n",
    "        self.prob_obj = prob_obj\n",
    "        # generate the lookup table for the ranges of x\n",
    "        self.fit()\n",
    "\n",
    "    def diff(self, x, a):\n",
    "        \"\"\" residual(?) for the fit method\n",
    "        \"\"\"\n",
    "        yt = self.prob_obj.normalised_cdf(x, self.prob_obj.params)\n",
    "        return (yt - a )**2\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\" Fits the inverse normalised cdf and generates a lookup table of sort\n",
    "        \"\"\"\n",
    "        # the for loop generates a lookup table correlating x and y based on the normalised cdf\n",
    "        for idx,x_value in enumerate(self.x):\n",
    "            res = sp_minimize(self.diff, 1.0, args=(x_value), method='Nelder-Mead', tol=1e-6)\n",
    "            self.y[idx] = res.x[0]\n",
    "\n",
    "    def get_value(self, p):\n",
    "        \"\"\" Gives corresponding attribute value depending on p (ranging from 0 to 1)\n",
    "        \"\"\"\n",
    "        x_copy = np.copy(self.x)\n",
    "        # find the index at which the x is equal to the input p\n",
    "        index = np.where(x_copy == p)\n",
    "        # gets the corresponding attribute value depending on the index\n",
    "        value = self.y[index]\n",
    "\n",
    "        return value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create object storing histogram datapoints\n",
    "accel_obj = Acceleration()\n",
    "print(accel_obj.bins)\n",
    "#load initial gaussian parameters\n",
    "param_obj = Gaussian_param()\n",
    "#create a probability function object for acceleration with its acceleration histogram data\n",
    "accel_prob_obj = Probability_Functions(accel_obj.bins, accel_obj.data_points,2)\n",
    "#fit the histogram\n",
    "hey = accel_prob_obj.NLLSR(param_obj)\n",
    "\n",
    "#plot the histogram, each gaussian component and the combined gaussian curve\n",
    "plt.plot(accel_prob_obj.x,accel_prob_obj.original_y,'b')\n",
    "yy = accel_prob_obj.eqn_model(hey.params)\n",
    "gaus_1 = accel_prob_obj.single_component(hey.params['alpha_1'],hey.params['sigma_1'],hey.params['meu_1'])\n",
    "gaus_2 = accel_prob_obj.single_component(hey.params['alpha_2'],hey.params['sigma_2'],hey.params['meu_2'])\n",
    "plt.plot(accel_prob_obj.x, yy,'r', label = 'best_fit')\n",
    "plt.plot(accel_prob_obj.x, gaus_1,'g', label = 'gaus_1')\n",
    "plt.plot(accel_prob_obj.x, gaus_2,'y', label = 'gaus_2')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "print(accel_prob_obj.cdf(0.8, hey.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0.33\n",
    "erf_param = (x - 0.83011822)/(0.21988047 * math.sqrt(2))\n",
    "print(erf_param)\n",
    "answer =  12.5916156 * (1 + special.erf(erf_param))\n",
    "print(answer)\n",
    "\n",
    "x = math.inf\n",
    "erf_param = (x - 0.83011822)/(0.21988047 * math.sqrt(2))\n",
    "print(erf_param)\n",
    "lim =  12.5916156 * (1 + special.erf(erf_param))\n",
    "print(answer/lim)\n",
    "\n",
    "\n",
    "x = np.linspace(0,2,1000)\n",
    "#plot the cdf of the sum of gaussian\n",
    "lim_inf_cdf = accel_prob_obj.cdf(math.inf, hey.params)\n",
    "yy = accel_prob_obj.normalised_cdf(x,hey.params)\n",
    "cdf_1 = accel_prob_obj.single_cdf_component(x,hey.params['alpha_1'],hey.params['sigma_1'],hey.params['meu_1'])/lim_inf_cdf\n",
    "cdf_2 = accel_prob_obj.single_cdf_component(x,hey.params['alpha_2'],hey.params['sigma_2'],hey.params['meu_2'])/lim_inf_cdf\n",
    "plt.plot(yy,x,'r', label = 'best_fit')\n",
    "plt.plot(cdf_1,x,'g', label = 'cdf_1')\n",
    "plt.plot(cdf_2,x,'y', label = 'cdf_2')\n",
    "plt.legend(loc='best')\n",
    "# plt.show()\n",
    "\n",
    "inv_cdf_obj = inv_cdf(accel_prob_obj)\n",
    "print(inv_cdf_obj.get_value(0))\n",
    "\n",
    "print(accel_prob_obj.normalised_cdf(0.718,hey.params))\n",
    "\n",
    "# q_1 = accel_prob_obj.single_quantile_component(x*lim_inf_cdf,hey.params['alpha_1'],hey.params['sigma_1'],hey.params['meu_1'])\n",
    "# q_2 = accel_prob_obj.single_quantile_component(x*lim_inf_cdf,hey.params['alpha_2'],hey.params['sigma_2'],hey.params['meu_2'])\n",
    "\n",
    "plt.plot(inv_cdf_obj.x,inv_cdf_obj.y,  label = 'minimized')\n",
    "# plt.plot(x,q_1,label = 'idk_1')\n",
    "# plt.plot(x,q_2,label = 'idk_2')\n",
    "plt.title(r'$f^{-1}(x)$')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend(loc='best')\n",
    "# # plt.savefig(\"function_inverse.png\", bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create object storing histogram datapoints\n",
    "cd_obj = Cruising_Duration()\n",
    "print(cd_obj.bins)\n",
    "#load initial gaussian parameters\n",
    "param_obj = Gaussian_param()\n",
    "#create a probability function object for acceleration with its acceleration histogram data\n",
    "cd_prob_obj = Probability_Functions(cd_obj.bins, cd_obj.data_points,2)\n",
    "#fit the histogram\n",
    "hey = cd_prob_obj.NLLSR(param_obj)\n",
    "\n",
    "#plot the histogram, each gaussian component and the combined gaussian curve\n",
    "plt.plot(cd_prob_obj.x,cd_prob_obj.original_y,'b')\n",
    "yy = cd_prob_obj.eqn_model(hey.params)\n",
    "gaus_1 = cd_prob_obj.single_component(hey.params['alpha_1'],hey.params['sigma_1'],hey.params['meu_1'])\n",
    "gaus_2 = cd_prob_obj.single_component(hey.params['alpha_2'],hey.params['sigma_2'],hey.params['meu_2'])\n",
    "plt.plot(cd_prob_obj.x, yy,'r', label = 'best_fit')\n",
    "plt.plot(cd_prob_obj.x, gaus_1,'g', label = 'gaus_1')\n",
    "plt.plot(cd_prob_obj.x, gaus_2,'y', label = 'gaus_2')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create object storing histogram datapoints\n",
    "avg_cs_obj = Average_Crusing_Speed()\n",
    "print(avg_cs_obj.bins)\n",
    "#load initial gaussian parameters\n",
    "param_obj = Gaussian_param()\n",
    "#create a probability function object for acceleration with its acceleration histogram data\n",
    "avg_cs_prob_obj = Probability_Functions(avg_cs_obj.bins, avg_cs_obj.data_points,2)\n",
    "#fit the histogram\n",
    "hey = avg_cs_prob_obj.NLLSR(param_obj)\n",
    "\n",
    "#plot the histogram, each gaussian component and the combined gaussian curve\n",
    "plt.plot(avg_cs_prob_obj.x,avg_cs_prob_obj.original_y,'b')\n",
    "yy = avg_cs_prob_obj.eqn_model(hey.params)\n",
    "gaus_1 = avg_cs_prob_obj.single_component(hey.params['alpha_1'],hey.params['sigma_1'],hey.params['meu_1'])\n",
    "gaus_2 = avg_cs_prob_obj.single_component(hey.params['alpha_2'],hey.params['sigma_2'],hey.params['meu_2'])\n",
    "plt.plot(avg_cs_prob_obj.x, yy,'r', label = 'best_fit')\n",
    "plt.plot(avg_cs_prob_obj.x, gaus_1,'g', label = 'gaus_1')\n",
    "plt.plot(avg_cs_prob_obj.x, gaus_2,'y', label = 'gaus_2')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create object storing histogram datapoints\n",
    "decel_obj = Deceleration()\n",
    "print(decel_obj.bins)\n",
    "#load initial gaussian parameters\n",
    "param_obj = Gaussian_param()\n",
    "#create a probability function object for deceleration with its deceleration histogram data\n",
    "decel_prob_obj = Probability_Functions(decel_obj.bins, decel_obj.data_points,2)\n",
    "#fit the histogram\n",
    "hey = decel_prob_obj.NLLSR(param_obj)\n",
    "\n",
    "#plot the histogram, each gaussian component and the combined gaussian curve\n",
    "plt.plot(decel_prob_obj.x,decel_prob_obj.original_y,'b')\n",
    "yy = decel_prob_obj.eqn_model(hey.params)\n",
    "gaus_1 = decel_prob_obj.single_component(hey.params['alpha_1'],hey.params['sigma_1'],hey.params['meu_1'])\n",
    "gaus_2 = decel_prob_obj.single_component(hey.params['alpha_2'],hey.params['sigma_2'],hey.params['meu_2'])\n",
    "plt.plot(decel_prob_obj.x, yy,'r', label = 'best_fit')\n",
    "plt.plot(decel_prob_obj.x, gaus_1,'g', label = 'gaus_1')\n",
    "plt.plot(decel_prob_obj.x, gaus_2,'y', label = 'gaus_2')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Velocity_Noise(object):\n",
    "    def __init__(self,t,y):\n",
    "        self.t = t\n",
    "        self.y = y\n",
    "        self.original_y = y\n",
    "        self.original_y_mean = self.original_y.mean()\n",
    "\n",
    "    def set_t(self, t):\n",
    "        \"\"\"Set t values\n",
    "        \"\"\"\n",
    "        self.t = t\n",
    "\n",
    "    def subtract_avg(self):\n",
    "        \"\"\"Removes the average speed from the observations\n",
    "        \"\"\"\n",
    "        self.y = self.y - self.original_y_mean\n",
    "        return self.y\n",
    "\n",
    "    def subtract(self, array):\n",
    "        self.y = self.y - array\n",
    "        return self.y\n",
    "\n",
    "    def single_component(self, A_i_FS, w_i_FS, phi_i_FS):\n",
    "        \"\"\" Returns a single velocity noise component as described in the sum of eqn (5)\n",
    "        \"\"\"\n",
    "        return A_i_FS * np.sin( (w_i_FS*self.t) + phi_i_FS )\n",
    "     \n",
    "    def eqn_model(self, params):\n",
    "        \"\"\" Returns the velocity noise FS model as described in eqn (5)\n",
    "        \"\"\"\n",
    "        # put all the paramters in a list\n",
    "        A_FS = [params['A1_FS'],params['A2_FS'],params['A3_FS']]\n",
    "        w_FS = [params['w1_FS'],params['w2_FS'],params['w3_FS']]\n",
    "        phi_FS = [params['phi1_FS'],params['phi2_FS'],params['phi3_FS']]\n",
    "\n",
    "        # equation (5), sum of 3 components\n",
    "        model = self.single_component(A_FS[0],w_FS[0], phi_FS[0])\n",
    "        model += self.single_component(A_FS[1],w_FS[1], phi_FS[1])\n",
    "        model += self.single_component(A_FS[2],w_FS[2], phi_FS[2])\n",
    "\n",
    "        return model\n",
    "\n",
    "    def final_curve(self):\n",
    "        \"\"\" Returns the final fitted curve\n",
    "        \"\"\"\n",
    "        final = self.eqn_model(self.LF_params.params)\n",
    "        final += self.eqn_model(self.MF_params.params)\n",
    "        final += self.eqn_model(self.HF_params.params)\n",
    "\n",
    "        return final\n",
    "\n",
    "    def fit_all(self, LF_param = LF_Noise(), MF_param = MF_Noise(), HF_param = HF_Noise()):\n",
    "        \"\"\" Fits the velicoty noise for all FS components\n",
    "        \"\"\"\n",
    "        self.LF_fit(LF_param)\n",
    "        self.subtract(self.eqn_model(self.LF_params.params))\n",
    "        self.MF_fit(MF_param)\n",
    "        self.subtract(self.eqn_model(self.MF_params.params))\n",
    "        self.HF_fit(HF_param)\n",
    "\n",
    "    def LF_fit(self, init_params = LF_Noise()):\n",
    "        \"\"\" Fits and returns the component parameters for LF noise\n",
    "        \"\"\"\n",
    "        self.LF_params = self.NLLSR(init_params)\n",
    "\n",
    "        return self.LF_params\n",
    "    \n",
    "    def MF_fit(self, init_params = MF_Noise()):\n",
    "        \"\"\" Fits and returns the component parameters for HF noise\n",
    "        \"\"\"\n",
    "        self.MF_params = self.NLLSR(init_params)\n",
    "\n",
    "        return self.MF_params\n",
    "\n",
    "    def HF_fit(self, init_params = HF_Noise()):\n",
    "        \"\"\" Fits and returns the component parameters for HF noise\n",
    "        \"\"\"\n",
    "        self.HF_params = self.NLLSR(init_params)\n",
    "\n",
    "        return self.HF_params\n",
    "\n",
    "    def fnc2min(self, params):\n",
    "        \"\"\" Returns the residuals (eqn 7) for the model for when running all 3 components at once\n",
    "        \"\"\"\n",
    "        return (self.y - self.eqn_model(params))\n",
    "\n",
    "    # def fnc2min(self, params):\n",
    "    #     \"\"\" Returns the residuals (eqn 7) for the model for when running one component at a time\n",
    "    #     \"\"\"\n",
    "    #     return (self.y - self.single_component(params['A_FS'], params['w_FS'], params['phi_FS']))\n",
    "\n",
    "\n",
    "    def NLLSR(self, LMparams):\n",
    "        \"\"\" Returns the result of the NLLSR using LMFit\n",
    "        \"\"\"\n",
    "        # uses least swuares method to minimize the parameters given by LMparams according to the residuals given by self.fnc2min\n",
    "        LMFitmin = Minimizer(self.fnc2min, LMparams)\n",
    "        LMFitResult = LMFitmin.minimize(method='least_squares')\n",
    "        lmfit.printfuncs.report_fit(LMFitResult.params)\n",
    "\n",
    "        return LMFitResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    # loads the csv file\n",
    "    subdir = 'caltrans_processed_drive_cycles/data/1135317_2'\n",
    "    file_name = '2012-04-06.csv'\n",
    "    data = load_csv_data(file_name, subdir)\n",
    "    # get a slice of the data with a relatively long driving pulse\n",
    "    # data = data.iloc[883:1302,:]\n",
    "    # # show the slice of data\n",
    "    # plt.plot(data.loc[:,'timestamp'], data.loc[:,'speed_mph'])\n",
    "    # plt.show()\n",
    "    # print(data)\n",
    "    # get the slice of ONLY cruising period\n",
    "    cruising_data = data.iloc[915:1285,:]\n",
    "    print(cruising_data)\n",
    "    # create a numpy array of just t values starting at t=1\n",
    "    t = np.linspace(1,len(cruising_data),len(cruising_data))\n",
    "    print(t)\n",
    "    # create a numpy array of speed_mph values and convert to m/s\n",
    "    y = cruising_data.loc[:,'speed_mph'].to_numpy()/2.237\n",
    "    print(y)\n",
    "    # interpolate linearly and make timesteps finer (0.001s)\n",
    "    from scipy.interpolate import interp1d\n",
    "    f = interp1d(t, y)\n",
    "    t = np.linspace(1,len(cruising_data),1000*len(cruising_data))\n",
    "    y = f(t)\n",
    "\n",
    "    # initialise the DP object\n",
    "    vn_obj = Velocity_Noise(t,y)\n",
    "    # deduct the average from the cruising period speed values (from fig3a to fig3b) and store as y\n",
    "    y = vn_obj.subtract_avg()\n",
    "\n",
    "    original_y = y\n",
    "    \n",
    "    # perform NLLSR with the initial parameters suggested by LMParams\n",
    "    hi = vn_obj.fit_all()\n",
    "    yy = vn_obj.final_curve()\n",
    "    \n",
    "    driving_pulse = DP(pulse_duration=500)\n",
    "    \n",
    "    plt.plot(t,y,'b')\n",
    "    plt.plot(t, yy,'r', label = 'best_fit')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    driving_pulse.generate_drive_cycle(vn_obj)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The code below is for when we are balancing all 3 components of a Frequency Spectrum (FS) at ONCE\n",
    "## Each block corresponds to one FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # loads the csv file\n",
    "    subdir = 'caltrans_processed_drive_cycles/data/1035198_1'\n",
    "    file_name = '2012-05-22.csv'\n",
    "    data = load_csv_data(file_name, subdir)\n",
    "    # get a slice of the data with a relatively long driving pulse\n",
    "    data = data.iloc[1002:1096,:]\n",
    "    # show the slice of data\n",
    "    plt.plot(data.loc[:,'timestamp'], data.loc[:,'speed_mph'])\n",
    "    plt.show()\n",
    "    # get the slice of ONLY cruising period\n",
    "    cruising_data = data.iloc[25:86,:]\n",
    "\n",
    "    # create a numpy array of just t values starting at t=1\n",
    "    t = np.linspace(1,len(cruising_data),len(cruising_data))\n",
    "    # create a numpy array of speed_mph values\n",
    "    y = cruising_data.loc[:,'speed_mph'].to_numpy()\n",
    "    # initialise the DP object\n",
    "    vn_obj = Velocity_Noise(t,y)\n",
    "    # deduct the average from the cruising period speed values (from fig3a to fig3b) and store as y\n",
    "    y = vn_obj.subtract_avg()\n",
    "\n",
    "    original_y = y\n",
    " \n",
    "    # perform NLLSR with the initial parameters suggested by LMParams\n",
    "    hi = vn_obj.LF_fit()\n",
    "    plt.plot(t,y,'b')\n",
    "\n",
    "    yy = hi.params['A1_FS'] * np.sin( (hi.params['w1_FS']*t) + hi.params['phi1_FS'])\n",
    "    yy = yy + hi.params['A2_FS'] * np.sin( (hi.params['w2_FS']*t) + hi.params['phi2_FS'])\n",
    "    yy = yy + hi.params['A3_FS'] * np.sin( (hi.params['w3_FS']*t) + hi.params['phi3_FS'])\n",
    "    plt.plot(t, yy,'r', label = 'best_fit')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    # remove previous component of LF spectrum\n",
    "    y = vn_obj.subtract(yy)\n",
    "    reconstructed = yy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # perform NLLSR with the initial parameters suggested by LMParams\n",
    "    hi2 = vn_obj.MF_fit()\n",
    "\n",
    "    plt.plot(t,y,'b')\n",
    "    yy = hi2.params['A1_FS'] * np.sin( (hi2.params['w1_FS']*t) + hi2.params['phi1_FS'])\n",
    "    yy = yy + hi2.params['A2_FS'] * np.sin( (hi2.params['w2_FS']*t) + hi2.params['phi2_FS'])\n",
    "    yy = yy + hi2.params['A3_FS'] * np.sin( (hi2.params['w3_FS']*t) + hi2.params['phi3_FS'])\n",
    "    plt.plot(t, yy,'r', label = 'best_fit')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    # remove previous component of LF spectrum\n",
    "    y = vn_obj.subtract(yy)\n",
    "    reconstructed += yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # perform NLLSR with the initial parameters suggested by LMParams\n",
    "    hi3 = vn_obj.HF_fit()\n",
    "    plt.plot(t,y,'b')\n",
    "    yy = hi3.params['A1_FS'] * np.sin( (hi3.params['w1_FS']*t) + hi3.params['phi1_FS'])\n",
    "    yy = yy + hi3.params['A2_FS'] * np.sin( (hi3.params['w2_FS']*t) + hi3.params['phi2_FS'])\n",
    "    yy = yy + hi3.params['A3_FS'] * np.sin( (hi3.params['w3_FS']*t) + hi3.params['phi3_FS'])\n",
    "    plt.plot(t, yy,'r', label = 'best_fit')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    # remove previous component of LF spectrum\n",
    "    y = vn_obj.subtract(yy)\n",
    "    reconstructed += yy\n",
    "\n",
    "\n",
    "    # create a numpy array of just new_t values starting at t=1\n",
    "    new_t = np.linspace(1,len(cruising_data),1000*len(cruising_data))\n",
    "    vn_obj.set_t(new_t)\n",
    "\n",
    "    plt.plot(t,original_y,'b')\n",
    "    plt.plot(new_t, vn_obj.final_curve(),'r', label = 'best_fit')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The code below is for when we are running one component at once \n",
    "## Each block is for one Frequency Spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # loads the csv file\n",
    "    subdir = 'caltrans_processed_drive_cycles/data/1035198_1'\n",
    "    file_name = '2012-05-22.csv'\n",
    "    data = load_csv_data(file_name, subdir)\n",
    "    # get a slice of the data with a relatively long driving pulse\n",
    "    data = data.iloc[1002:1096,:]\n",
    "    plt.plot(data.loc[:,'timestamp'], data.loc[:,'speed_mph'])\n",
    "    plt.show()\n",
    "    # get the slice of ONLY cruising period\n",
    "    cruising_data = data.iloc[25:86,:]\n",
    "\n",
    "    # create a numpy array of just t values starting at t=1\n",
    "    t = np.linspace(1,len(cruising_data),len(cruising_data))\n",
    "    # create a numpy array of speed_mph values\n",
    "    y = cruising_data.loc[:,'speed_mph'].to_numpy()\n",
    "    # initialise the DP object\n",
    "    vn_obj = Velocity_Noise(t,y)\n",
    "    # deduct the average from the cruising period speed values (from fig3a to fig3b) and store as y\n",
    "    y = vn_obj.subtract_avg()\n",
    "\n",
    "    original_y = y\n",
    "    \n",
    "    # perform NLLSR with the initial parameters suggested by LMParams\n",
    "    hi = vn_obj.NLLSR(LF_Noise(1))\n",
    "    plt.plot(t,y,'b')\n",
    "    yy = vn_obj.single_component(hi.params['A_FS'],hi.params['w_FS'],hi.params['phi_FS'])\n",
    "    plt.plot(t, yy,'r', label = 'best_fit')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    # remove previous component of LF spectrum\n",
    "    y = vn_obj.subtract(yy)\n",
    "    reconstructed = yy\n",
    "\n",
    "    # perform NLLSR with the initial parameters suggested by LMParams\n",
    "    hi = vn_obj.NLLSR(LF_Noise(2))\n",
    "    plt.plot(t,y,'b')\n",
    "    yy = vn_obj.single_component(hi.params['A_FS'],hi.params['w_FS'],hi.params['phi_FS'])\n",
    "    plt.plot(t, yy,'r', label = 'best_fit')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    # remove previous component of LF spectrum\n",
    "    y = vn_obj.subtract(yy)\n",
    "    reconstructed += yy\n",
    "\n",
    "    # perform NLLSR with the initial parameters suggested by LMParams\n",
    "    hi = vn_obj.NLLSR(LF_Noise(3))\n",
    "    plt.plot(t,y,'b')\n",
    "    yy = vn_obj.single_component(hi.params['A_FS'],hi.params['w_FS'],hi.params['phi_FS'])\n",
    "    plt.plot(t, yy,'r', label = 'best_fit')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    # remove previous component of LF spectrum\n",
    "    y = vn_obj.subtract(yy)\n",
    "    reconstructed += yy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # perform NLLSR with the initial parameters suggested by LMParams\n",
    "    hi = vn_obj.NLLSR(MF_Noise(1))\n",
    "    plt.plot(t,y,'b')\n",
    "    yy = vn_obj.single_component(hi.params['A_FS'],hi.params['w_FS'],hi.params['phi_FS'])\n",
    "    plt.plot(t, yy,'r', label = 'best_fit')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    # remove previous component of MF spectrum\n",
    "    y = vn_obj.subtract(yy)\n",
    "    reconstructed += yy\n",
    "\n",
    "    # perform NLLSR with the initial parameters suggested by LMParams\n",
    "    hi = vn_obj.NLLSR(MF_Noise(2))\n",
    "    plt.plot(t,y,'b')\n",
    "    yy = vn_obj.single_component(hi.params['A_FS'],hi.params['w_FS'],hi.params['phi_FS'])\n",
    "    plt.plot(t, yy,'r', label = 'best_fit')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    # remove previous component of MF spectrum\n",
    "    y = vn_obj.subtract(yy)\n",
    "    reconstructed += yy\n",
    "\n",
    "    # perform NLLSR with the initial parameters suggested by LMParams\n",
    "    hi = vn_obj.NLLSR(MF_Noise(3))\n",
    "    plt.plot(t,y,'b')\n",
    "    yy = vn_obj.single_component(hi.params['A_FS'],hi.params['w_FS'],hi.params['phi_FS'])\n",
    "    plt.plot(t, yy,'r', label = 'best_fit')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    # remove previous component of MF spectrum\n",
    "    y = vn_obj.subtract(yy)\n",
    "    reconstructed += yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # perform NLLSR with the initial parameters suggested by LMParams\n",
    "    hi = vn_obj.NLLSR(HF_Noise(1))\n",
    "    plt.plot(t,y,'b')\n",
    "    yy = vn_obj.single_component(hi.params['A_FS'],hi.params['w_FS'],hi.params['phi_FS'])\n",
    "    plt.plot(t, yy,'r', label = 'best_fit')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    # remove previous component of HF spectrum\n",
    "    y = vn_obj.subtract(yy)\n",
    "    reconstructed += yy\n",
    "\n",
    "    # perform NLLSR with the initial parameters suggested by LMParams\n",
    "    hi = vn_obj.NLLSR(HF_Noise(2))\n",
    "    plt.plot(t,y,'b')\n",
    "    yy = vn_obj.single_component(hi.params['A_FS'],hi.params['w_FS'],hi.params['phi_FS'])\n",
    "    plt.plot(t, yy,'r', label = 'best_fit')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    # remove previous component of HF spectrum\n",
    "    y = vn_obj.subtract(yy)\n",
    "    reconstructed += yy\n",
    "\n",
    "    # perform NLLSR with the initial parameters suggested by LMParams\n",
    "    hi = vn_obj.NLLSR(HF_Noise(3))\n",
    "    plt.plot(t,y,'b')\n",
    "    yy = vn_obj.single_component(hi.params['A_FS'],hi.params['w_FS'],hi.params['phi_FS'])\n",
    "    plt.plot(t, yy,'r', label = 'best_fit')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    # remove previous component of HF spectrum\n",
    "    y = vn_obj.subtract(yy)\n",
    "    reconstructed += yy\n",
    "\n",
    "    plt.plot(t,original_y,'b')\n",
    "    plt.plot(t, reconstructed,'r', label = 'best_fit')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}